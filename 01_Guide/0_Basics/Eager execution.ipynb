{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7e09a13",
   "metadata": {},
   "source": [
    "íŒŒì¼ ì„¤ëª… : TF 2.xë¶€í„°ëŠ” ì§ê´€ì ìœ¼ë¡œ ì½”ë”©í•˜ê³  ë””ë²„ê¹…í•˜ê¸° íŽ¸í•´ì¡Œë‹¤!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f37f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # 1ë²ˆ GPU ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aac1c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 23:40:05.685432: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763908805.727978   25924 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763908805.740584   25924 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1763908805.818352   25924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763908805.818362   25924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763908805.818364   25924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763908805.818366   25924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-23 23:40:05.827749: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cProfile # íŒŒì´ì¬ ë‚´ìž¥ ì„±ëŠ¥ ë¶„ì„ ë„êµ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714e7e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íƒì§€ëœ GPU ê°œìˆ˜: 1ê°œ\n",
      "íƒì§€ëœ GPU ëª©ë¡: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "'''gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            # â˜… í•µì‹¬: ë©”ëª¨ë¦¬ë¥¼ í•œ ë²ˆì— ë‹¤ ìž¡ì§€ ë§ê³ , í•„ìš”í•  ë•Œë§ˆë‹¤ ëŠ˜ë ¤ë‚˜ê°€ë¼!\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "print(f\"íƒì§€ëœ GPU ê°œìˆ˜: {len(gpus)}ê°œ\") \n",
    "print(f\"íƒì§€ëœ GPU ëª©ë¡: {gpus}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008ab2e9",
   "metadata": {},
   "source": [
    "ì„¤ì¹˜ì™€ ê¸°ë³¸ ì‚¬ìš©ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f29c111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í…ì„œí”Œë¡œ 2.0ì—ì„œ ì¦‰ì‹œ ì‹¤í–‰ì€ ê¸°ë³¸ìœ¼ë¡œ í™œì„±í™”ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.\n",
    "tf.executing_eagerly()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b887606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, [[4.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763908807.970377   25924 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22323 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "x = [[2.]] #2ì°¨ì› í–‰ë ¬(í…ì„œ) ì •ì˜ (1x1 í–‰ë ¬)\n",
    "m = tf.matmul(x, x) # í–‰ë ¬ ê³± ìˆ˜í–‰\n",
    "print(f\"hello, {m.numpy()}\") # .numpy()ë¥¼ ë¶™ì´ë©´ tf.Tensor(...) ê»ë°ê¸°ë¥¼ ë²—ê¸°ê³  ìˆ«ìžë§Œ ë³´ì—¬ì¤Œ (ndarray ë°˜í™˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76ffe261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2],\n",
    "                 [3,4]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cab694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2  6]\n",
      " [12 20]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# ë¸Œë¡œë“œìºìŠ¤íŒ…(Broadcasting) ì§€ì› -> ìŠ¤ì¹¼ë¼ 1ì„ [[1,1],[1,1]]ë¡œ ë³€í™˜ì‹œì¼œ ì—°ì‚°\n",
    "b = tf.add(a, 1)\n",
    "print(b)\n",
    "# ì—°ì‚°ìž ì˜¤ë²„ë¡œë”© ì§€ì› -> ì›ì†Œë³„ ê³±ì…ˆ ì˜ˆì‹œ\n",
    "print(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673e0a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [12 20]]\n"
     ]
    }
   ],
   "source": [
    "# NumPyê°’ ì‚¬ìš© -> í•˜ì§€ë§Œ Numpy ì—°ì‚°ì€ CPUì—ì„œ ëŒê³  TensorëŠ” GPUì—ì„œ ëˆë‹¤ëŠ” ì  ì£¼ì˜\n",
    "import numpy as np\n",
    "\n",
    "c = np.multiply(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111cd5af",
   "metadata": {},
   "source": [
    "ë™ì ì¸ ì œì–´ íë¦„ : í…ì„œí”Œë¡œìš°ë¼ê³  í•´ì„œ íŠ¹ë³„í•œ ì œì–´ë¬¸ì´ ìžˆëŠ” ê²Œ ì•„ë‹ˆë¼, ê·¸ëƒ¥ íŒŒì´ì¬ ì§œë“¯ì´ ë¡œì§ ì§œë©´ ì•Œì•„ì„œ ëŒì•„ê°‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62f7e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizzbuzz(max_num):\n",
    "  counter = tf.constant(0)\n",
    "  max_num = tf.convert_to_tensor(max_num)\n",
    "  for num in range(1, max_num.numpy()+1):\n",
    "    num = tf.constant(num)\n",
    "    if int(num % 3) == 0 and int(num % 5) == 0:\n",
    "      print('FizzBuzz')\n",
    "    elif int(num % 3) == 0:\n",
    "      print('Fizz')\n",
    "    elif int(num % 5) == 0:\n",
    "      print('Buzz')\n",
    "    else:\n",
    "      print(num.numpy())\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd317cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n",
      "FizzBuzz\n"
     ]
    }
   ],
   "source": [
    "fizzbuzz(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f3e57",
   "metadata": {},
   "source": [
    "# ì¦‰ì‹œ í›ˆë ¨\n",
    "ê·¸ëž˜ë””ì–¸íŠ¸ ê³„ì‚°í•˜ê¸° : ðŸ“Œ 3ë‹¨ ìš”ì•½\n",
    "1. ë…¹í™” (Record): with tf.GradientTape() as tape: ë¸”ë¡ ì•ˆì—ì„œ ì¼ì–´ë‚˜ëŠ” ëª¨ë“  ìˆ˜í•™ ì—°ì‚°ì„ í…Œì´í”„ì— ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "\n",
    "2. ë¯¸ë¶„ (Calculate): ê¸°ë¡ëœ í…Œì´í”„ë¥¼ ë˜ê°ê¸°í•´ì„œ ê¸°ìš¸ê¸°(Gradient)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (tape.gradient())\n",
    "\n",
    "3. íê¸° (Discard): ê³„ì‚°ì´ ëë‚˜ë©´ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ í…Œì´í”„ëŠ” ìžë™ìœ¼ë¡œ ì“°ë ˆê¸°í†µì— ë²„ë ¤ì§‘ë‹ˆë‹¤. (1íšŒìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7da434f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]]\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([[1.0]])\n",
    "with tf.GradientTape() as tape:\n",
    "  loss = w * w\n",
    "\n",
    "grad = tape.gradient(loss, w)\n",
    "print(grad.numpy())  # => tf.Tensor([[ 2.]], shape=(1, 1), dtype=float32) ë¯¸ë¶„ê°’ 2wì— 1ëŒ€ìž…í•œ ê²°ê³¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac39a7",
   "metadata": {},
   "source": [
    "Model training : í‘œì¤€ MNIST ì†ê¸€ì”¨ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë‹¤ì¸µ ëª¨ë¸ì„ ìƒì„±, ì¦‰ì‹œ ì‹¤í–‰ í™˜ê²½ì—ì„œ í›ˆë ¨ê°€ëŠ¥í•œ ê·¸ëž˜í”„ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ ì˜µí‹°ë§ˆì´ì €(optimizer)ì™€ ì¸µ APIë¥¼ ë³´ì—¬ì¤Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7beae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# mnist ë°ì´í„° ê°€ì ¸ì˜¤ê¸°(RAM) ë° í¬ë§· ë§žì¶”ê¸° (í•™ìŠµìš©),(í…ŒìŠ¤íŠ¸ìš©) -> í…ŒìŠ¤íŠ¸ìš©ì€ _ë¡œ ì•ˆê°€ì ¸ì˜´\n",
    "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# í†µì§œ ë°ì´í„°(6ë§Œ ê°œ)ë¥¼ 'í•˜ë‚˜ì”© êº¼ë‚´ ì“¸ ìˆ˜ ìžˆëŠ” ìŠ¤íŠ¸ë¦¼(Stream)' í˜•íƒœë¡œ ë§Œë“­ë‹ˆë‹¤.\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32), # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ë³€í™˜) -> ì°¨ì› ì¶”ê°€(newaxis), ì •ê·œí™”(/255), í˜•ë³€í™˜(float32)\n",
    "   tf.cast(mnist_labels,tf.int64))) # label í˜•ë³€í™˜(int64)\n",
    "dataset = dataset.shuffle(1000).batch(32) # ë°ì´í„°ë¥¼ ë¬´ìž‘ìœ„ë¡œ ì„žê¸°(bufferí¬ê¸° 1000), ì´ë¯¸ì§€ 32ìž¥ì„ í•œ ë¬¶ìŒ(Batch)ìœ¼ë¡œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f7f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab602/miniconda3/envs/tutorial/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ìƒì„±\n",
    "mnist_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu',\n",
    "                         input_shape=(None, None, 1)),\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(10) # Torchì™€ ë‹¤ë¥´ê²Œ ìž…ë ¥ ì±„ë„ ìˆ˜ ì ì„ í•„ìš” X\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae0d5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763909658.234932   25924 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¡œì§“:  [[-0.00281734 -0.03198805 -0.00116722  0.02181125 -0.01129573  0.02348453\n",
      "  -0.00529278 -0.00614655 -0.03023855 -0.0026798 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 23:54:18.514850: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# ì¦‰ì‹œ ì‹¤í–‰ì—ì„œëŠ” í›ˆë ¨ì„ í•˜ì§€ ì•Šì•„ë„ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³  ê²°ê³¼ë¥¼ ì ê²€í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤\n",
    "for images,labels in dataset.take(1):\n",
    "  print(\"ë¡œì§“: \", mnist_model(images[0:1]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¼€ë¼ìŠ¤ ëª¨ë¸ì€ ìžì²´ì ì¸ í›ˆë ¨ ë©”ì„œë“œ(fit)ì„ í¬í•¨í•˜ê³  ìžˆì§€ë§Œ ë•Œë¡œëŠ” ì¢€ ë” ìˆ˜ì •í•  í•„ìš”ê°€ ìžˆìŠµë‹ˆë‹¤. ë‹¤ìŒì€ ì¦‰ì‹œ ì‹¤í–‰ì„ í™œìš©í•œ ë°˜ë³µì ì¸ í›ˆë ¨ì˜ ì˜ˆ\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ac7edc",
   "metadata": {},
   "source": [
    "model.fit()ê³¼ ê°™ì€ ì½”ë“œ : [ìˆœì „íŒŒ(Forward) $\\rightarrow$ ì†ì‹¤ ê³„ì‚°(Loss) $\\rightarrow$ ì—­ì „íŒŒ(Backward) $\\rightarrow$ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸(Update)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14d43c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape: # ì—°ì‚° ê¸°ë¡ ì‹œìž‘\n",
    "    logits = mnist_model(images, training=True) # Forward Pass, í•™ìŠµëª¨ë“œ\n",
    "\n",
    "    # ê²°ê³¼ì˜ í˜•íƒœë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ ë‹¨ì–¸ë¬¸(Debugging) ì¶”ê°€\n",
    "    tf.debugging.assert_equal(logits.shape, (32, 10))\n",
    "\n",
    "    loss_value = loss_object(labels, logits) # Loss Calculation\n",
    "\n",
    "  loss_history.append(loss_value.numpy().mean())\n",
    "  grads = tape.gradient(loss_value, mnist_model.trainable_variables) # Backpropagation\n",
    "  optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables)) # Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "612b57e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  for epoch in range(3):\n",
    "    for (batch, (images, labels)) in enumerate(dataset):\n",
    "      train_step(images, labels)\n",
    "    print ('ì—í¬í¬ {} ì¢…ë£Œ'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e60f4b90",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_25924/3364925475.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train()\n",
      "\u001b[32m/tmp/ipykernel_25924/3440171021.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m train():\n\u001b[32m      2\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;28;01min\u001b[39;00m range(\u001b[32m3\u001b[39m):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (batch, (images, labels)) \u001b[38;5;28;01min\u001b[39;00m enumerate(dataset):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m       train_step(images, labels)\n\u001b[32m      5\u001b[39m     print (\u001b[33m'ì—í¬í¬ {} ì¢…ë£Œ'\u001b[39m.format(epoch))\n",
      "\u001b[32m/tmp/ipykernel_25924/592474530.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(images, labels)\u001b[39m\n\u001b[32m      8\u001b[39m     loss_value = loss_object(labels, logits) \u001b[38;5;66;03m# Loss Calculation\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m   loss_history.append(loss_value.numpy().mean())\n\u001b[32m     11\u001b[39m   grads = tape.gradient(loss_value, mnist_model.trainable_variables) \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m   optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables)) \u001b[38;5;66;03m# Gradient Descent\u001b[39;00m\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, grads_and_vars)\u001b[39m\n\u001b[32m    460\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m apply_gradients(self, grads_and_vars):\n\u001b[32m    461\u001b[39m         grads, trainable_variables = zip(*grads_and_vars)\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m         self.apply(grads, trainable_variables)\n\u001b[32m    463\u001b[39m         \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[32m    464\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._iterations\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, grads, trainable_variables)\u001b[39m\n\u001b[32m    522\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m scale \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    523\u001b[39m                     grads = [g \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m g / scale \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;28;01min\u001b[39;00m grads]\n\u001b[32m    524\u001b[39m \n\u001b[32m    525\u001b[39m                 \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m                 self._backend_apply_gradients(grads, trainable_variables)\n\u001b[32m    527\u001b[39m                 \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[32m    528\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;28;01min\u001b[39;00m trainable_variables:\n\u001b[32m    529\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m variable.constraint \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, grads, trainable_variables)\u001b[39m\n\u001b[32m    588\u001b[39m             grads = self._clip_gradients(grads)\n\u001b[32m    589\u001b[39m             self._apply_weight_decay(trainable_variables)\n\u001b[32m    590\u001b[39m \n\u001b[32m    591\u001b[39m             \u001b[38;5;66;03m# Run update step.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m             self._backend_update_step(\n\u001b[32m    593\u001b[39m                 grads, trainable_variables, self.learning_rate\n\u001b[32m    594\u001b[39m             )\n\u001b[32m    595\u001b[39m \n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, grads, trainable_variables, learning_rate)\u001b[39m\n\u001b[32m    116\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;28;01min\u001b[39;00m trainable_variables\n\u001b[32m    117\u001b[39m         ]\n\u001b[32m    118\u001b[39m         grads_and_vars = list(zip(grads, trainable_variables))\n\u001b[32m    119\u001b[39m         grads_and_vars = self._all_reduce_sum_gradients(grads_and_vars)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[32m    121\u001b[39m             self._distributed_tf_update_step,\n\u001b[32m    122\u001b[39m             self._distribution_strategy,\n\u001b[32m    123\u001b[39m             grads_and_vars,\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(fn, strategy, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m   Returns:\n\u001b[32m     48\u001b[39m     The \u001b[38;5;28;01mreturn\u001b[39;00m value of the `fn` call.\n\u001b[32m     49\u001b[39m   \"\"\"\n\u001b[32m     50\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(strategy, *args, **kwargs)\n\u001b[32m     52\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     53\u001b[39m     return distribute_lib.get_replica_context().merge_call(\n\u001b[32m     54\u001b[39m         fn, args=args, kwargs=kwargs)\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, distribution, grads_and_vars, learning_rate)\u001b[39m\n\u001b[32m    130\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m apply_grad_to_update_var(var, grad, learning_rate):\n\u001b[32m    131\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.update_step(grad, var, learning_rate)\n\u001b[32m    132\u001b[39m \n\u001b[32m    133\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;28;01min\u001b[39;00m grads_and_vars:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m             distribution.extended.update(\n\u001b[32m    135\u001b[39m                 var,\n\u001b[32m    136\u001b[39m                 apply_grad_to_update_var,\n\u001b[32m    137\u001b[39m                 args=(grad, learning_rate),\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, var, fn, args, kwargs, group)\u001b[39m\n\u001b[32m   3001\u001b[39m         _get_default_replica_context()):\n\u001b[32m   3002\u001b[39m       fn = autograph.tf_convert(\n\u001b[32m   3003\u001b[39m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[32m   3004\u001b[39m       \u001b[38;5;28;01mwith\u001b[39;00m self._container_strategy().scope():\n\u001b[32m-> \u001b[39m\u001b[32m3005\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._update(var, fn, args, kwargs, group)\n\u001b[32m   3006\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3007\u001b[39m       return self._replica_ctx_update(\n\u001b[32m   3008\u001b[39m           var, fn, args=args, kwargs=kwargs, group=group)\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, var, fn, args, kwargs, group)\u001b[39m\n\u001b[32m   4072\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m _update(self, var, fn, args, kwargs, group):\n\u001b[32m   4073\u001b[39m     \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[32m   4074\u001b[39m     \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4075\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[39m\n\u001b[32m   4077\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m _update_non_slot(self, colocate_with, fn, args, kwargs, should_group):\n\u001b[32m   4078\u001b[39m     \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[32m   4079\u001b[39m     \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[32m   4080\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[32m-> \u001b[39m\u001b[32m4081\u001b[39m       result = fn(*args, **kwargs)\n\u001b[32m   4082\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[32m   4083\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m   4084\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    595\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.UNSPECIFIED):\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(var, grad, learning_rate)\u001b[39m\n\u001b[32m    130\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m apply_grad_to_update_var(var, grad, learning_rate):\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.update_step(grad, var, learning_rate)\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/keras/src/optimizers/adam.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, gradient, variable, learning_rate)\u001b[39m\n\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m         alpha = lr * ops.sqrt(\u001b[32m1\u001b[39m - beta_2_power) / (\u001b[32m1\u001b[39m - beta_1_power)\n\u001b[32m    118\u001b[39m \n\u001b[32m    119\u001b[39m         self.assign_add(\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m             m, ops.multiply(ops.subtract(gradient, m), \u001b[32m1\u001b[39m - self.beta_1)\n\u001b[32m    121\u001b[39m         )\n\u001b[32m    122\u001b[39m         self.assign_add(\n\u001b[32m    123\u001b[39m             v,\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/keras/src/ops/numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m   6812\u001b[39m         Output tensor, element-wise difference of `x1` \u001b[38;5;28;01mand\u001b[39;00m `x2`.\n\u001b[32m   6813\u001b[39m     \"\"\"\n\u001b[32m   6814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x1, x2)):\n\u001b[32m   6815\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m Subtract().symbolic_call(x1, x2)\n\u001b[32m-> \u001b[39m\u001b[32m6816\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m backend.numpy.subtract(x1, x2)\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/keras/src/backend/tensorflow/sparse.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m    489\u001b[39m                     x1 = tf.convert_to_tensor(x1)\n\u001b[32m    490\u001b[39m             \u001b[38;5;28;01melif\u001b[39;00m isinstance(x2, tf.IndexedSlices):\n\u001b[32m    491\u001b[39m                 \u001b[38;5;66;03m# x2 is an IndexedSlices, densify.\u001b[39;00m\n\u001b[32m    492\u001b[39m                 x2 = tf.convert_to_tensor(x2)\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m func(x1, x2)\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m    485\u001b[39m         getattr(x2, \u001b[33m\"dtype\"\u001b[39m, type(x2)),\n\u001b[32m    486\u001b[39m     )\n\u001b[32m    487\u001b[39m     x1 = convert_to_tensor(x1, dtype)\n\u001b[32m    488\u001b[39m     x2 = convert_to_tensor(x2, dtype)\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.subtract(x1, x2)\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1257\u001b[39m \n\u001b[32m   1258\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1262\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/tensorflow/python/ops/math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m    541\u001b[39m @tf_export(\u001b[33m\"math.subtract\"\u001b[39m, \u001b[33m\"subtract\"\u001b[39m)\n\u001b[32m    542\u001b[39m @dispatch.register_binary_elementwise_api\n\u001b[32m    543\u001b[39m @dispatch.add_dispatch_support\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m subtract(x, y, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops.sub(x, y, name)\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m op(*args, **kwargs)\n\u001b[32m    143\u001b[39m     bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m     bound_arguments.apply_defaults()\n\u001b[32m    145\u001b[39m     bound_kwargs = bound_arguments.arguments\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m  12309\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m  12310\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m  12311\u001b[39m       return sub_eager_fallback(\n\u001b[32m  12312\u001b[39m           x, y, name=name, ctx=_ctx)\n\u001b[32m> \u001b[39m\u001b[32m12313\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._SymbolicException:\n\u001b[32m  12314\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[32m  12315\u001b[39m   \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[32m  12316\u001b[39m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[32m~/miniconda3/envs/tutorial/lib/python3.11/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, name, ctx)\u001b[39m\n\u001b[32m> \u001b[39m\u001b[32m12330\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m sub_eager_fallback(x: Annotated[Any, TV_Sub_T], y: Annotated[Any, TV_Sub_T], name, ctx) -> Annotated[Any, TV_Sub_T]:\n\u001b[32m  12331\u001b[39m   _attr_T, _inputs_T = _execute.args_to_matching_eager([x, y], ctx, [_dtypes.bfloat16, _dtypes.half, _dtypes.float32, _dtypes.float64, _dtypes.uint8, _dtypes.int8, _dtypes.uint16, _dtypes.int16, _dtypes.int32, _dtypes.int64, _dtypes.complex64, _dtypes.complex128, _dtypes.uint32, _dtypes.uint64, ])\n\u001b[32m  12332\u001b[39m   (x, y) = _inputs_T\n\u001b[32m  12333\u001b[39m   _inputs_flat = [x, y]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff66f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
